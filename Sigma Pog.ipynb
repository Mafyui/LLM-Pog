{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8660db51-f114-43ee-9b79-7204f719c587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from Single_Block_Fortnite import EmbeddingNN, AttentionNN, NormNN, FFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b796f9a1-60aa-4e45-a807-56cba8d48e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'z', ',', 'j', 'E', 'b', 'i', '$', 'M', ' ', 'f', 'V', 'U', 's', 'Z', '3', 'H', 'B', 'n', 'r', 'G', 'T', 'Q', 'Y', 'x', 'o', 'I', 'd', 'm', 'q', '-', 'u', 'D', 'y', \"'\", 'c', 'a', 'l', 'v', 'X', 'L', '!', 't', 'K', 'F', 'k', 'e', '.', 'w', 'R', 'C', 'p', 'h', ';', 'S', 'O', '\\n', 'P', 'W', ':', 'A', '?', 'N', 'J', 'g', '&'} 65\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "with open(\"C:/Users/PC/Desktop/Important Data/Shakespeare_Data.txt\", \"r\") as f:\n",
    "    text = f.read()  \n",
    "    chars = set(text)\n",
    "    vocab_size = len(chars)\n",
    "print(chars, vocab_size)\n",
    "\n",
    "decode_dict = { i : chars for i , chars in enumerate(chars)}\n",
    "encode_dict = { chars : i for i , chars in enumerate(chars)}\n",
    "\n",
    "encode = lambda text : [encode_dict[i] for i in text]\n",
    "decode = lambda text : ''.join([decode_dict[i] for i in text])\n",
    "\n",
    "encoded_text = encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cec522e-f44e-4802-ad93-2e5d2e5478bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "hidden_dim = 128\n",
    "max_sequence_length = 512\n",
    "num_of_head = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37099373-797e-4610-b91b-82fb6a6ccdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attention = AttentionNN(hidden_dim, num_heads)\n",
    "        self.ffn = FFN(hidden_dim)\n",
    "        self.norm1 = NormNN(hidden_dim)\n",
    "        self.norm2 = NormNN(hidden_dim)\n",
    "\n",
    "    def forward(self, X):\n",
    "        attention_output = self.attention(X)\n",
    "        X = X + attention_output\n",
    "\n",
    "        pog_X = self.norm1(X)\n",
    "\n",
    "        pogger_X = self.ffn(pog_X) + pog_X\n",
    "\n",
    "        poggers_X = self.norm2(pogger_X)\n",
    "\n",
    "        return poggers_X\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3109a766-a275-494c-87f4-5b0697aa84ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = EmbeddingNN(vocab_size, hidden_dim, max_sequence_length).to(device)\n",
    "\n",
    "data = torch.tensor(encoded_text , dtype = torch.long).to(device)\n",
    "\n",
    "\n",
    "seq_len = 64\n",
    "for i in range(0, len(X) - seq_len, seq_len):\n",
    "    batch_x = data[i:i+seq_len].unsqueeze(0)\n",
    "    batch_x = batch_x.repeat(batch_size, 1)\n",
    "\n",
    "    pos = torch.arange(seq_len, device=device).unsqueeze(0).repeat(batch_size, 1)\n",
    "\n",
    "\n",
    "    combined_embeddings = embedding_model(batch_x, pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4f0abb5-b123-4934-93a6-aa6b3d98582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,vocab_size , hidden_dim,num_heads, N):\n",
    "        super().__init__()\n",
    "\n",
    "        self.blocks = nn.ModuleList(TransformerBlock(hidden_dim, num_heads) for i in range(N))\n",
    "        self.linear = nn.Linear(hidden_dim,vocab_size)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for block in self.blocks:\n",
    "            X = block(X)\n",
    "        X = self.linear(X)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6356431-8af6-4192-9fd7-f5cdf6be7a70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
